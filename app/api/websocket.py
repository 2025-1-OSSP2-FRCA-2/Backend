# # from fastapi import APIRouter, WebSocket, WebSocketDisconnect
# # from PIL import Image
# # import io
# # import os
# # import numpy as np
# # import torch
# # from collections import deque
# # from app.models.efficientNetPrac import VideoEfficientNet, transform

# # router = APIRouter(prefix="/ws")

# # # ëª¨ë¸ ì´ˆê¸°í™”
# # device = 'cuda' if torch.cuda.is_available() else 'cpu'
# # model = VideoEfficientNet(pretrained=True).to(device)
# # # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
# # model_path = os.path.join(os.path.dirname(__file__), '..', 'models', 'weights', 'model.pt')
# # model.load_state_dict(torch.load(model_path, map_location=device))
# # model.eval()

# # @router.websocket("/student")
# # async def websocket_endpoint(websocket: WebSocket):
# #     await websocket.accept()
# #     print("ğŸŸ¢ í•™ìƒ WebSocket ì—°ê²°ë¨")

# #     # í”„ë ˆì„ ë²„í¼ ì´ˆê¸°í™”
# #     frame_buffer = deque(maxlen=8)  # clip_len=8ì— ë§ì¶¤

# #     try:
# #         while True:
# #             print("ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
# #             data = await websocket.receive_bytes()
# #             # ì´ë¯¸ì§€ ì²˜ë¦¬
# #             image = Image.open(io.BytesIO(data)).convert("RGB")
# #             # ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
# #             img_tensor = transform(image)
# #             # í”„ë ˆì„ ë²„í¼ì— ì¶”ê°€
# #             frame_buffer.append(img_tensor)
# #             # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì¶”ë¡ 
# #             if len(frame_buffer) == 8:
# #                 # [8, C, H, W] -> [1, C, 8, H, W]
# #                 clip = torch.stack(list(frame_buffer), dim=0)
# #                 clip = clip.permute(1, 0, 2, 3).unsqueeze(0)
                
# #                 with torch.no_grad():
# #                     logits = model(clip)
# #                     prob = torch.sigmoid(logits)
# #                     preds = prob.gt(0.5).sum(dim=2).squeeze(0).tolist()
                
# #                 emotions = ['boredom', 'confusion', 'engagement', 'frustration']
# #                 results = {emotion: pred for emotion, pred in zip(emotions, preds)}
# #                 print("â†’ ê°ì • ìƒíƒœ ì˜ˆì¸¡:", results)


# #     except WebSocketDisconnect:
# #         print("ğŸ”´ WebSocket ì—°ê²° ì¢…ë£Œë¨")

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from PIL import Image
import io
import os
import torch
import asyncio
from collections import deque
from app.models.efficientNetPrac import VideoEfficientNet, transform

router = APIRouter(prefix="/ws")

# ëª¨ë¸ ì´ˆê¸°í™”
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = VideoEfficientNet(pretrained=True).to(device)
model_path = os.path.join(os.path.dirname(__file__), '..', 'models', 'weights', 'model.pt')
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

@router.websocket("/student")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("ğŸŸ¢ í•™ìƒ WebSocket ì—°ê²°ë¨")

    # ë¹„ë™ê¸° í”„ë ˆì„ íì™€ ë²„í¼
    frame_queue: asyncio.Queue = asyncio.Queue()
    frame_buffer = deque(maxlen=8)

    async def receiver():
        """WebSocketì—ì„œ ë“¤ì–´ì˜¤ëŠ” í”„ë ˆì„ì„ íì— ë„£ëŠ” íƒœìŠ¤í¬"""
        try:
            while True:
                data = await websocket.receive_bytes()
                image = Image.open(io.BytesIO(data)).convert("RGB")
                tensor = transform(image)
                # íì— (ì…ë ¥ì‹œê°, tensor) íŠœí”Œë¡œ ì €ì¥
                await frame_queue.put((asyncio.get_event_loop().time(), tensor))
        except WebSocketDisconnect:
            # ì—°ê²° ëŠê¹€ì„ ì•Œë¦¬ê¸° ìœ„í•´ Noneì„ í‘¸ì‹œ
            await frame_queue.put(None)
            print("ğŸ”´ ìˆ˜ì‹  íƒœìŠ¤í¬ ì¢…ë£Œ")

    async def inferencer():
        """0.5ì´ˆë§ˆë‹¤ íì—ì„œ ìµœì‹  í”„ë ˆì„ 8ê°œ ë½‘ì•„ ì¶”ë¡ í•˜ëŠ” íƒœìŠ¤í¬"""
        try:
            while True:
                # 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ì‹¤í–‰
                await asyncio.sleep(0.5)

                # íì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ì•„ì´í…œ êº¼ë‚´ê¸°
                while not frame_queue.empty():
                    item = await frame_queue.get()
                    if item is None:
                        # ìˆ˜ì‹ ì´ ì¢…ë£Œëœ ì‹ í˜¸
                        return
                    _, tensor = item
                    frame_buffer.append(tensor)

                # ë²„í¼ê°€ ê½‰ ì°¼ì„ ë•Œë§Œ ì¶”ë¡ 
                if len(frame_buffer) == frame_buffer.maxlen:
                    # [8, C, H, W] â†’ [1, C, 8, H, W]
                    clip = torch.stack(list(frame_buffer), dim=0)
                    clip = clip.permute(1, 0, 2, 3).unsqueeze(0).to(device)
                    with torch.no_grad():
                        logits = model(clip)
                        prob = torch.sigmoid(logits)
                        preds = prob.gt(0.5).sum(dim=2).squeeze(0).tolist()

                    emotions = ['boredom', 'confusion', 'engagement', 'frustration']
                    results = {e: p for e, p in zip(emotions, preds)}
                    print("â†’ ê°ì • ìƒíƒœ ì˜ˆì¸¡:", results)

        except Exception as e:
            print("âš ï¸ ì¶”ë¡  íƒœìŠ¤í¬ ì—ëŸ¬:", e)

    # ìˆ˜ì‹ Â·ì¶”ë¡  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰
    recv_task = asyncio.create_task(receiver())
    infer_task = asyncio.create_task(inferencer())

    # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    done, pending = await asyncio.wait(
        {recv_task, infer_task},
        return_when=asyncio.FIRST_COMPLETED,
    )

    # ë‚¨ì€ íƒœìŠ¤í¬ê°€ ìˆìœ¼ë©´ ì·¨ì†Œ
    for task in pending:
        task.cancel()

    print("ğŸ”´ WebSocket ì²˜ë¦¬ ì¢…ë£Œ")
