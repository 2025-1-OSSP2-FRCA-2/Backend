
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from PIL import Image
import io
import os
import torch
import asyncio
from collections import deque
from app.models.efficientNetPrac import VideoEfficientNet, transform

router = APIRouter(prefix="/ws")

# ëª¨ë¸ ì´ˆê¸°í™”
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = VideoEfficientNet(pretrained=True).to(device)
model_path = os.path.join(os.path.dirname(__file__), '..', 'models', 'weights', 'model.pt')
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

@router.websocket("/student")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("ğŸŸ¢ í•™ìƒ WebSocket ì—°ê²°ë¨")

    # ë¹„ë™ê¸° í”„ë ˆì„ íì™€ ë²„í¼
    frame_queue: asyncio.Queue = asyncio.Queue()
    frame_buffer = deque(maxlen=8)

    async def receiver():
        """WebSocketì—ì„œ ë“¤ì–´ì˜¤ëŠ” í”„ë ˆì„ì„ íì— ë„£ëŠ” íƒœìŠ¤í¬"""
        try:
            while True:
                data = await websocket.receive_bytes()
                image = Image.open(io.BytesIO(data)).convert("RGB")
                tensor = transform(image)
                # íì— (ì…ë ¥ì‹œê°, tensor) íŠœí”Œë¡œ ì €ì¥
                await frame_queue.put((asyncio.get_event_loop().time(), tensor))
        except WebSocketDisconnect:
            # ì—°ê²° ëŠê¹€ì„ ì•Œë¦¬ê¸° ìœ„í•´ Noneì„ í‘¸ì‹œ
            await frame_queue.put(None)
            print("ğŸ”´ ìˆ˜ì‹  íƒœìŠ¤í¬ ì¢…ë£Œ")

    async def inferencer():
        """0.5ì´ˆë§ˆë‹¤ íì—ì„œ ìµœì‹  í”„ë ˆì„ 8ê°œ ë½‘ì•„ ì¶”ë¡ í•˜ëŠ” íƒœìŠ¤í¬"""
        try:
            while True:
                # 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ì‹¤í–‰
                await asyncio.sleep(0.5)

                # íì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ì•„ì´í…œ êº¼ë‚´ê¸°
                while not frame_queue.empty():
                    item = await frame_queue.get()
                    if item is None:
                        # ìˆ˜ì‹ ì´ ì¢…ë£Œëœ ì‹ í˜¸
                        return
                    _, tensor = item
                    frame_buffer.append(tensor)

                # ë²„í¼ê°€ ê½‰ ì°¼ì„ ë•Œë§Œ ì¶”ë¡ 
                if len(frame_buffer) == frame_buffer.maxlen:
                    # [8, C, H, W] â†’ [1, C, 8, H, W]
                    clip = torch.stack(list(frame_buffer), dim=0)
                    clip = clip.permute(1, 0, 2, 3).unsqueeze(0).to(device)
                    with torch.no_grad():
                        logits = model(clip)
                        prob = torch.sigmoid(logits)
                        preds = prob.gt(0.5).sum(dim=2).squeeze(0).tolist()

                    emotions = ['boredom', 'confusion', 'engagement', 'frustration']
                    results = {e: p for e, p in zip(emotions, preds)}
                    print("â†’ ê°ì • ìƒíƒœ ì˜ˆì¸¡:", results)

        except Exception as e:
            print("âš ï¸ ì¶”ë¡  íƒœìŠ¤í¬ ì—ëŸ¬:", e)

    # ìˆ˜ì‹ Â·ì¶”ë¡  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰
    recv_task = asyncio.create_task(receiver())
    infer_task = asyncio.create_task(inferencer())

    # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    done, pending = await asyncio.wait(
        {recv_task, infer_task},
        return_when=asyncio.FIRST_COMPLETED,
    )

    # ë‚¨ì€ íƒœìŠ¤í¬ê°€ ìˆìœ¼ë©´ ì·¨ì†Œ
    for task in pending:
        task.cancel()

    print("ğŸ”´ WebSocket ì²˜ë¦¬ ì¢…ë£Œ")
