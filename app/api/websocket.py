from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from PIL import Image
import io
import os
import numpy as np
import torch
from collections import deque
from app.models.efficientNetPrac import VideoEfficientNet, transform

router = APIRouter(prefix="/ws")

# ëª¨ë¸ ì´ˆê¸°í™”
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = VideoEfficientNet(pretrained=True).to(device)
# í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
model_path = os.path.join(os.path.dirname(__file__), '..', 'models', 'weights', 'model.pt')
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

@router.websocket("/student")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("ğŸŸ¢ í•™ìƒ WebSocket ì—°ê²°ë¨")

    # í”„ë ˆì„ ë²„í¼ ì´ˆê¸°í™”
    frame_buffer = deque(maxlen=8)  # clip_len=8ì— ë§ì¶¤

    try:
        while True:
            print("ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
            data = await websocket.receive_bytes()
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image = Image.open(io.BytesIO(data)).convert("RGB")
            # ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            img_tensor = transform(image)
            # í”„ë ˆì„ ë²„í¼ì— ì¶”ê°€
            frame_buffer.append(img_tensor)
            # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì¶”ë¡ 
            if len(frame_buffer) == 8:
                # [8, C, H, W] -> [1, C, 8, H, W]
                clip = torch.stack(list(frame_buffer), dim=0)
                clip = clip.permute(1, 0, 2, 3).unsqueeze(0)
                
                with torch.no_grad():
                    logits = model(clip)
                    prob = torch.sigmoid(logits)
                    preds = prob.gt(0.5).sum(dim=2).squeeze(0).tolist()
                
                emotions = ['boredom', 'confusion', 'engagement', 'frustration']
                results = {emotion: pred for emotion, pred in zip(emotions, preds)}
                print("â†’ ê°ì • ìƒíƒœ ì˜ˆì¸¡:", results)


    except WebSocketDisconnect:
        print("ğŸ”´ WebSocket ì—°ê²° ì¢…ë£Œë¨")